{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Black Friday\n",
    "### Problen Statement\n",
    "A retail company “ABC Private Limited” wants to understand the customer purchase behaviour (specifically, purchase amount) against various products of different categories. They have shared purchase summary of various customers for selected high volume products from last month.\n",
    "The data set also contains customer demographics (age, gender, marital status, city_type, stay_in_current_city), product details (product_id and product category) and Total purchase_amount from last month.\n",
    "Now, they want to build a model to predict the purchase amount of customer against various products which will help them to create personalized offer for customers against different products."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import all necessary package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = pd.read_csv(r'./Data/train.csv')\n",
    "dataset_test = pd.read_csv(r'./Data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check first 5 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "550068\n",
      "233599\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>City_Category</th>\n",
       "      <th>Stay_In_Current_City_Years</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Product_Category_1</th>\n",
       "      <th>Product_Category_2</th>\n",
       "      <th>Product_Category_3</th>\n",
       "      <th>Purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00069042</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00248942</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00087842</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00085442</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000002</td>\n",
       "      <td>P00285442</td>\n",
       "      <td>M</td>\n",
       "      <td>55+</td>\n",
       "      <td>16</td>\n",
       "      <td>C</td>\n",
       "      <td>4+</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_ID Product_ID Gender   Age  Occupation City_Category  \\\n",
       "0  1000001  P00069042      F  0-17          10             A   \n",
       "1  1000001  P00248942      F  0-17          10             A   \n",
       "2  1000001  P00087842      F  0-17          10             A   \n",
       "3  1000001  P00085442      F  0-17          10             A   \n",
       "4  1000002  P00285442      M   55+          16             C   \n",
       "\n",
       "  Stay_In_Current_City_Years  Marital_Status  Product_Category_1  \\\n",
       "0                          2               0                   3   \n",
       "1                          2               0                   1   \n",
       "2                          2               0                  12   \n",
       "3                          2               0                  12   \n",
       "4                         4+               0                   8   \n",
       "\n",
       "   Product_Category_2  Product_Category_3  Purchase  \n",
       "0                 NaN                 NaN      8370  \n",
       "1                 6.0                14.0     15200  \n",
       "2                 NaN                 NaN      1422  \n",
       "3                14.0                 NaN      1057  \n",
       "4                 NaN                 NaN      7969  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(dataset_train))\n",
    "print(len(dataset_test))\n",
    "dataset_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "store categorical variables column name and dictionary with column to unique value mapping associated with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender ['F' 'M']\n",
      "Age ['0-17' '18-25' '26-35' '36-45' '46-50' '51-55' '55+']\n",
      "Occupation [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "City_Category ['A' 'B' 'C']\n",
      "Stay_In_Current_City_Years ['0' '1' '2' '3' '4+']\n",
      "Marital_Status [0 1]\n",
      "Product_Category_1 [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20]\n",
      "Product_Category_2 [ 0.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17. 18.]\n",
      "Product_Category_3 [ 0.  3.  4.  5.  6.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17. 18.]\n"
     ]
    }
   ],
   "source": [
    "columns = dataset_train.columns\n",
    "dic_columnwise_acceped_value = {}\n",
    "for i in columns[2:-1] :\n",
    "    temp1 = dataset_train[i].unique()\n",
    "    temp2 = dataset_test[i].unique()\n",
    "    try :\n",
    "        if np.isnan(temp1).any() and np.isnan(temp2).any() :\n",
    "            temp1 = temp1[~np.isnan(temp1)]\n",
    "    except TypeError :\n",
    "        pass\n",
    "    tem_dup =  np.hstack([temp1, temp2])\n",
    "    tem_dup = np.unique(tem_dup)\n",
    "    dic_columnwise_acceped_value[i] = list(tem_dup)\n",
    "    print(i,tem_dup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check and print if any column contain null or NaN value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User_ID                       0\n",
      "Product_ID                    0\n",
      "Gender                        0\n",
      "Age                           0\n",
      "Occupation                    0\n",
      "City_Category                 0\n",
      "Stay_In_Current_City_Years    0\n",
      "Marital_Status                0\n",
      "Product_Category_1            0\n",
      "Product_Category_2            0\n",
      "Product_Category_3            0\n",
      "Purchase                      0\n",
      "dtype: int64\n",
      "User_ID                       0\n",
      "Product_ID                    0\n",
      "Gender                        0\n",
      "Age                           0\n",
      "Occupation                    0\n",
      "City_Category                 0\n",
      "Stay_In_Current_City_Years    0\n",
      "Marital_Status                0\n",
      "Product_Category_1            0\n",
      "Product_Category_2            0\n",
      "Product_Category_3            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(dataset_train.isna().sum())\n",
    "print(dataset_test.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case product_category_2 and product_category_3 contain null value\n",
    "Create SimpleImputer class to replace NaN to 0 so that later on it can be HotEncoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_NaN(data, columns, *args) :    \n",
    "    mp = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=0)\n",
    "    transformed_val = mp.fit_transform(data.iloc[:,[columns.get_loc(i) for i in list(args)]].values)\n",
    "    df = data.copy()\n",
    "    df[list(args)] = transformed_val\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "replacing Nan from two columns Product_Category_2 Product_Category_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = replace_NaN(dataset_train, dataset_train.columns, 'Product_Category_2', 'Product_Category_3')\n",
    "dataset_test = replace_NaN(dataset_test, dataset_test.columns, 'Product_Category_2', 'Product_Category_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>City_Category</th>\n",
       "      <th>Stay_In_Current_City_Years</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Product_Category_1</th>\n",
       "      <th>Product_Category_2</th>\n",
       "      <th>Product_Category_3</th>\n",
       "      <th>Purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00069042</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00248942</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00087842</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000001</td>\n",
       "      <td>P00085442</td>\n",
       "      <td>F</td>\n",
       "      <td>0-17</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000002</td>\n",
       "      <td>P00285442</td>\n",
       "      <td>M</td>\n",
       "      <td>55+</td>\n",
       "      <td>16</td>\n",
       "      <td>C</td>\n",
       "      <td>4+</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1000003</td>\n",
       "      <td>P00193542</td>\n",
       "      <td>M</td>\n",
       "      <td>26-35</td>\n",
       "      <td>15</td>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_ID Product_ID Gender    Age  Occupation City_Category  \\\n",
       "0  1000001  P00069042      F   0-17          10             A   \n",
       "1  1000001  P00248942      F   0-17          10             A   \n",
       "2  1000001  P00087842      F   0-17          10             A   \n",
       "3  1000001  P00085442      F   0-17          10             A   \n",
       "4  1000002  P00285442      M    55+          16             C   \n",
       "5  1000003  P00193542      M  26-35          15             A   \n",
       "\n",
       "  Stay_In_Current_City_Years  Marital_Status  Product_Category_1  \\\n",
       "0                          2               0                   3   \n",
       "1                          2               0                   1   \n",
       "2                          2               0                  12   \n",
       "3                          2               0                  12   \n",
       "4                         4+               0                   8   \n",
       "5                          3               0                   1   \n",
       "\n",
       "   Product_Category_2  Product_Category_3  Purchase  \n",
       "0                 0.0                 0.0      8370  \n",
       "1                 6.0                14.0     15200  \n",
       "2                 0.0                 0.0      1422  \n",
       "3                14.0                 0.0      1057  \n",
       "4                 0.0                 0.0      7969  \n",
       "5                 2.0                 0.0     15227  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for each categorical column we created n-1 number of dummy variable which contain either 0 or 1\n",
    "create a function which take data, column Names list, column name (In which we want to perform an operation)\n",
    "and remove column name which we want to remove in order to avoid dummy variable trap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_column_with_Dummy_Columns(data, columns, column_name, remove_column_val, dtype=int) :\n",
    "    temp = pd.get_dummies(data[column_name], prefix=column_name, dtype=dtype)\n",
    "    col = list(temp.columns)\n",
    "    removed_col = column_name+'_'+remove_column_val\n",
    "    removed_col_index = col.index(removed_col)\n",
    "    temp = temp[col[:removed_col_index] + col[removed_col_index+1:]] # removing to avoid dummy variable trap\n",
    "    previous = data[columns[:columns.index(column_name)]]\n",
    "    after = data[columns[columns.index(column_name)+1:]]\n",
    "    previous = previous.join(temp)\n",
    "    previous = previous.join(after)\n",
    "    return previous"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For One categorical column of training data create hotencoded column from function replace_column_with_Dummy_Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dummy_dataset(data, columns, cat_col_list) :\n",
    "    col = cat_col_list\n",
    "    df = data[list(filter(lambda x: x not in cat_col_list, columns))]\n",
    "    for i in cat_col_list :\n",
    "        dic = data[i].value_counts().to_dict()\n",
    "        max_key = max(dic, key=dic.get) # for non column removal it automatically contain maximim number\n",
    "        # so we dont need to remove it seperately\n",
    "        data = replace_column_with_Dummy_Columns(data, col, i, str(max_key))\n",
    "        col = list(data.columns)\n",
    "    df= df.join(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterating through each categorical column in training and testing set to get dummy coded column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hotencoded_dataset(columns, dataset_train, dataset_test) :  \n",
    "    column = list(columns)\n",
    "    data_label = dataset_train[[column[-1]]]\n",
    "    slice_index = len(dataset_train)\n",
    "    df = dataset_train[column[:-1]] # seperate label column\n",
    "    df = pd.concat([df, dataset_test], ignore_index=True) # merge 2 dataframe\n",
    "    df = get_dummy_dataset(df, column[:-1], column[2:-1])\n",
    "    sliced_train_data = df.loc[:slice_index-1]\n",
    "    sliced_test_data = df.loc[slice_index:]\n",
    "    sliced_train_data = pd.concat([sliced_train_data, data_label], sort=False, axis=1)\n",
    "    return sliced_train_data, sliced_test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create hot encoded data for training and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test = get_hotencoded_dataset(columns, dataset_train, dataset_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create generic model object which store all the Information of related model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelObject :\n",
    "    def __init__(self, name) :\n",
    "        self._name = name\n",
    "        self._cross_validation_score = None\n",
    "        self._model = None\n",
    "    @property\n",
    "    def name(self) :\n",
    "        return self._name\n",
    "    @property\n",
    "    def cross_validation_score(self) :\n",
    "        return self._cross_validation_score\n",
    "    @cross_validation_score.setter\n",
    "    def cross_validation_score(self, value) :\n",
    "        try :\n",
    "            self._cross_validation_score = value\n",
    "        except Exception as e:\n",
    "            raise Exception('value object is not in format',e)\n",
    "    @property\n",
    "    def model(self) :\n",
    "        return self._model\n",
    "    @model.setter\n",
    "    def model(self, value) :\n",
    "        self._model = value\n",
    "        self._cross_validation_score = None\n",
    "    def __str__(self) :\n",
    "        res = '\\n'\n",
    "        res += 'Model Name :- ' + self._name + '\\n'\n",
    "        res += 'cross validation score :- ' + str(self._cross_validation_score) + '\\n'\n",
    "        if self._model != None :\n",
    "            res += 'Model Parameter ' + str(self._model.get_params) + '\\n'\n",
    "        else :\n",
    "            res += '\\n'\n",
    "        return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since data_test doesn't contain target variable thats why I am splitting data_train to X_train, y_train, X_test and y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a function which eleminate feature from backward and return train, test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_list(data) :\n",
    "    return list(data.columns)\n",
    "def get_dataSet_with_eliminated_features(data, label_col, eliminated_features_count=0, ahead_start=2) :\n",
    "    f_count = len(get_feature_list(data))\n",
    "    if label_col < 0 or label_col >= f_count:\n",
    "        return None\n",
    "    if (eliminated_features_count  < 0) or (eliminated_features_count > (f_count - ahead_start - 1)) :\n",
    "        return None\n",
    "    col_index_list = list(range(ahead_start, f_count))\n",
    "    del col_index_list[col_index_list.index(label_col)]\n",
    "    col_index_list = col_index_list if eliminated_features_count == 0 else col_index_list[:-eliminated_features_count]\n",
    "    #print(col_index_list)\n",
    "    #print(label_col)\n",
    "    X = data.iloc[:,col_index_list].values\n",
    "    y = data.iloc[:, label_col].values\n",
    "    X_train, X_test, y_train , y_test = model_selection.train_test_split(X, y, test_size = 0.2, random_state=0)\n",
    "    return (X_train, X_test, y_train , y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For selecting feature we will go through backward elemination methods. since except gender all \n",
    "categorical variable has more then 2 level so we can't apply biserial correlation for binary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Models\n",
    "### 1.Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimal_modellr(X_train, y_train) :\n",
    "    seed_k_fold = 7\n",
    "    no_of_split = 10\n",
    "    scoring = 'neg_mean_squared_error'\n",
    "    lr = ModelObject('Linear Regression')\n",
    "    kfold = model_selection.KFold(n_splits= no_of_split, random_state=seed_k_fold)\n",
    "    lr.model = LinearRegression(fit_intercept=True, normalize=False, copy_X=True, n_jobs=None)\n",
    "    cv_results = -model_selection.cross_val_score(lr.model, X_train, y_train,cv=kfold, scoring=scoring)\n",
    "    \"\"\"The unified scoring API always maximizes the score, so scores which need to be minimized are negated\n",
    "    in order for the unified scoring API to work correctly. The score that is returned is therefore negated\n",
    "    when it is a score that should be minimized and left positive if it is a score that should be maximized.\"\"\"\n",
    "    cv_results.sort(axis=-1, kind='mergesort', order=None)\n",
    "    lr.cross_validation_score = cv_results\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get linear model without any regularization and check its RMSE as the performance metrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cr mean - 8889010.0525569\n",
      "cr mean - 8889119.329643253\n",
      "cr mean - 8914314.381786192\n",
      "cr mean - 8914245.64527319\n",
      "cr mean - 8922265.748940362\n"
     ]
    }
   ],
   "source": [
    "col_len = len(get_feature_list(data_train))\n",
    "for i in range(5) :\n",
    "    data = get_dataSet_with_eliminated_features(data_train, col_len - 1, i)\n",
    "    if data is not None :\n",
    "        X_train, X_test, y_train , y_test = data[0], data[1], data[2], data[3]\n",
    "        lr = get_optimal_modellr(X_train, y_train)\n",
    "        print('cr mean -',lr.cross_validation_score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see if we remove feature model performance goes down so we will continue building our model with all feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_dataSet_with_eliminated_features(data_train, col_len - 1, 0)\n",
    "if data is not None :\n",
    "    X_train, X_test, y_train , y_test = data[0], data[1], data[2], data[3]\n",
    "else :\n",
    "    assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ridge_regression_model(lambda_val) :\n",
    "    return Ridge(alpha = lambda_val, fit_intercept=True, normalize=False, copy_X=True,\n",
    "                         max_iter=None, tol=0.001, solver='auto', random_state=0)\n",
    "def get_optimal_model_ridge(X_train, y_train, verbose=True, lambda_start=0.001, lambda_stop=1.2, no_split=10) :\n",
    "    seed_k_fold = 7\n",
    "    no_of_split = no_split\n",
    "    range_lambda  = np.logspace(lambda_start, lambda_stop, num=no_split)\n",
    "    kf = model_selection.KFold(n_splits= no_of_split, random_state=seed_k_fold)\n",
    "    index = 0\n",
    "    val_score_list = []\n",
    "    #Applying cross validation for getting appropriate value of lambda\n",
    "    for train_index, test_index in kf.split(X_train):\n",
    "        #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        X_tr, X_tst = X_train[train_index], X_train[test_index]\n",
    "        y_tr, y_tst = y_train[train_index], y_train[test_index]\n",
    "        temp = get_ridge_regression_model(range_lambda[index])\n",
    "        temp.fit(X_tr,y_tr)\n",
    "        predicted = temp.predict(X_tst)\n",
    "        validation_score = mean_squared_error(y_tst, predicted)\n",
    "        val_score_list.append(validation_score)\n",
    "        if verbose :\n",
    "            print('lambda - '+str(range_lambda[index]) + '--validation score '+str(validation_score))\n",
    "        index += 1\n",
    "    min_val_score_index = val_score_list.index(min(val_score_list))\n",
    "    lambda_optimal = range_lambda[min_val_score_index]\n",
    "    ridge_reg = ModelObject('Ridge Regression')\n",
    "    ridge_reg.model = get_ridge_regression_model(lambda_optimal)\n",
    "    ridge_reg.cross_validation_score = val_score_list[min_val_score_index]\n",
    "    return ridge_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda - 1.0023052380778996--validation score 8922647.530799838\n",
      "lambda - 1.362141492331366--validation score 8844968.085384028\n",
      "lambda - 1.8511620758251646--validation score 8846008.861777883\n",
      "lambda - 2.515745280696361--validation score 8825670.343655938\n",
      "lambda - 3.4189196073092853--validation score 8841837.975315006\n",
      "lambda - 4.646341333097262--validation score 8893420.155536015\n",
      "lambda - 6.314418080347418--validation score 8865594.740417538\n",
      "lambda - 8.581348815120236--validation score 8947751.548640985\n",
      "lambda - 11.66212730131956--validation score 9029363.807581186\n",
      "lambda - 15.848931924611133--validation score 8871717.69304336\n",
      "8884201.382101309\n"
     ]
    }
   ],
   "source": [
    "# fitting optimal model\n",
    "rr = get_optimal_model_ridge(X_train, y_train, verbose=True)\n",
    "rr.model.fit(X_train,y_train)\n",
    "predicted = rr.model.predict(X_test)\n",
    "print(mean_squared_error(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lasso_regression_model(lambda_val) :\n",
    "    #precompute - Whether to use a precomputed Gram matrix to speed up calculations\n",
    "    # warm_start - When set to True, reuse the solution of the previous call to fit as initialization\n",
    "    return Lasso(alpha = lambda_val, fit_intercept=True, normalize=False, precompute=False,\n",
    "                            copy_X=True, max_iter=None, tol=0.0001, warm_start=False, positive=False,\n",
    "                            random_state=0, selection='cyclic')\n",
    "def get_optimal_model_lasso(X_train, y_train, verbose=True, lambda_start=0.001, lambda_stop=1.2, no_split=10) :\n",
    "    seed_k_fold = 7\n",
    "    no_of_split = no_split\n",
    "    range_lambda  = np.logspace(lambda_start, lambda_stop, num=no_split)\n",
    "    kf = model_selection.KFold(n_splits= no_of_split, random_state=seed_k_fold)\n",
    "    index = 0\n",
    "    val_score_list = []\n",
    "    #Applying cross validation for getting appropriate value of lambda\n",
    "    for train_index, test_index in kf.split(X_train):\n",
    "        #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        X_tr, X_tst = X_train[train_index], X_train[test_index]\n",
    "        y_tr, y_tst = y_train[train_index], y_train[test_index]\n",
    "        y_tr = y_tr.astype('float')\n",
    "        y_tst = y_tst.astype('float')\n",
    "        temp =  get_lasso_regression_model(range_lambda[index])\n",
    "        temp.fit(X_tr, y_tr)\n",
    "        #temp.fit([[0,0], [1, 1], [2, 2]], [0, 1, 2])\n",
    "        predicted = temp.predict(X_tst)\n",
    "        #validation_score = mean_squared_error(y_tst, predicted)\n",
    "        #val_score_list.append(validation_score)\n",
    "        if verbose :\n",
    "            print('lambda - '+str(range_lambda[index]) + '--validation score '+str(validation_score))\n",
    "        index += 1\n",
    "    min_val_score_index = val_score_list.index(min(val_score_list))\n",
    "    lambda_optimal = range_lambda[min_val_score_index]\n",
    "    lasso_reg = ModelObject('Lasso Regression')\n",
    "    lasso_reg.model = get_lasso_regression_model(lambda_optimal)\n",
    "    lasso_reg.cross_validation_score = val_score_list[min_val_score_index]\n",
    "    return lasso_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "an integer is required",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-125-d6eb1c3a9099>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# fitting optimal model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_optimal_model_lasso\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-124-1c7511be3781>\u001b[0m in \u001b[0;36mget_optimal_model_lasso\u001b[1;34m(X_train, y_train, verbose, lambda_start, lambda_stop, no_split)\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0my_tst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_tst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'float'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mtemp\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mget_lasso_regression_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange_lambda\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mtemp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_tr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[1;31m#temp.fit([[0,0], [1, 1], [2, 2]], [0, 1, 2])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mpredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtemp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_tst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, check_input)\u001b[0m\n\u001b[0;32m    750\u001b[0m                           \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    751\u001b[0m                           \u001b[0mselection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselection\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 752\u001b[1;33m                           check_input=False)\n\u001b[0m\u001b[0;32m    753\u001b[0m             \u001b[0mcoef_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mthis_coef\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    754\u001b[0m             \u001b[0mdual_gaps_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mthis_dual_gap\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py\u001b[0m in \u001b[0;36menet_path\u001b[1;34m(X, y, l1_ratio, eps, n_alphas, alphas, precompute, Xy, copy_X, coef_init, verbose, return_n_iter, positive, check_input, **params)\u001b[0m\n\u001b[0;32m    473\u001b[0m             model = cd_fast.enet_coordinate_descent(\n\u001b[0;32m    474\u001b[0m                 \u001b[0mcoef_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml1_reg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml2_reg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrng\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 475\u001b[1;33m                 positive)\n\u001b[0m\u001b[0;32m    476\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m             raise ValueError(\"Precompute should be one of True, False, \"\n",
      "\u001b[1;32msklearn\\linear_model\\cd_fast.pyx\u001b[0m in \u001b[0;36msklearn.linear_model.cd_fast.enet_coordinate_descent\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: an integer is required"
     ]
    }
   ],
   "source": [
    "# fitting optimal model\n",
    "lr = get_optimal_model_lasso(X_train, y_train, verbose=True)\n",
    "lr.model.fit(X_train,y_train)\n",
    "predicted = lr.model.predict(X_test)\n",
    "print(mean_squared_error(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_svr_model(c=1.0) :\n",
    "    #C = it is a hyperparameter that controls how much we penalize our use of slack variables\n",
    "    #slack variable - as a value ζthat, roughly, indicates how much we must move our point so that\n",
    "    #it is correctly and confidently classified\n",
    "    # gamma - gamma controls the shape of the \"peaks\" where you raise the points\n",
    "    kernel = 'rbf' # 'sigmoid' 'linear' 'poly'\n",
    "    degree = 3 # only when kernel is poly\n",
    "    gamma = 'auto'\n",
    "    return SVR(kernel=kernel, degree=degree, gamma=gamma, coef0=0.0, tol=0.001, C=c,\n",
    "               epsilon=0.1, shrinking=True, cache_size=200, verbose=False, max_iter=-1)\n",
    "def get_optimal_model_svr(X_train, y_train, verbose=True, c_start=0.001, c_stop=1.2, no_split=10) :\n",
    "    seed_k_fold = 7\n",
    "    no_of_split = no_split\n",
    "    range_c  = np.logspace(c_start, c_stop, num=no_split)\n",
    "    kf = model_selection.KFold(n_splits= no_of_split, random_state=seed_k_fold)\n",
    "    index = 0\n",
    "    val_score_list = []\n",
    "    #Applying cross validation for getting appropriate value of c\n",
    "    for train_index, test_index in kf.split(X_train):\n",
    "        #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        X_tr, X_tst = X_train[train_index], X_train[test_index]\n",
    "        y_tr, y_tst = y_train[train_index], y_train[test_index]\n",
    "        temp =  get_svr_model(range_c[index])\n",
    "        temp.fit(X_tr, y_tr)\n",
    "        predicted = temp.predict(X_tst)\n",
    "        validation_score = mean_squared_error(y_tst, predicted)\n",
    "        val_score_list.append(validation_score)\n",
    "        if verbose :\n",
    "            print('lambda - '+str(range_lambda[index]) + '--validation score '+str(validation_score))\n",
    "        index += 1\n",
    "    min_val_score_index = val_score_list.index(min(val_score_list))\n",
    "    c_optimal = range_c[min_val_score_index]\n",
    "    svr_reg = ModelObject('SVR')\n",
    "    svr_reg.model = get_svr_model(c_optimal)\n",
    "    svr_reg.cross_validation_score = val_score_list[min_val_score_index]\n",
    "    return svr_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# fitting optimal model\n",
    "svr = get_optimal_model_svr(X_train, y_train, verbose=True)\n",
    "svr.model.fit(X_train,y_train)\n",
    "predicted = svr.model.predict(X_test)\n",
    "print(mean_squared_error(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best value obtained by lambda is 2.515745280696361 putting this to get optimal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_knn_model(k=5) :\n",
    "    algo = 'brute' #{‘auto’, ‘ball_tree’, ‘kd_tree’, ‘brute’}\n",
    "    return KNeighborsRegressor(n_neighbors=k, weights='uniform', algorithm=algo, leaf_size=30, p=2,\n",
    "                               metric='minkowski', metric_params=None, n_jobs=-1)\n",
    "def get_optimal_model_knn(X_train, y_train, ,x_test verbose=True, k_stop=1.2) :\n",
    "    range_k  = np.arange(1,k_stop, num=no_split)\n",
    "    #Applying cross validation for getting appropriate value of c\n",
    "    for i in range_k:\n",
    "        temp =  get_knn_model(i)\n",
    "        temp.fit(X_tr, y_tr)\n",
    "        if verbose :\n",
    "            print('lambda - '+str(range_lambda[index]) + '--validation score '+str(validation_score))\n",
    "        index += 1\n",
    "    svr_reg = ModelObject('KNN')\n",
    "    svr_reg.model = get_knn_model(c_optimal)\n",
    "    svr_reg.cross_validation_score = val_score_list[min_val_score_index]\n",
    "    return svr_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B  C\n",
       "0  1  5  6\n",
       "1  2  6  4\n",
       "2  3  7  3\n",
       "3  4  8  2"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame({'A':[1,2,3,4]})\n",
    "df2 = pd.DataFrame({'B':[5,6,7,8], 'C': [6,4,3,2]})\n",
    "dd = pd.concat([df1, df2], sort=False, axis=1)\n",
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A\n",
       "0  1\n",
       "1  2\n",
       "2  3\n",
       "3  4\n",
       "4  5\n",
       "5  6\n",
       "6  7\n",
       "7  8"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame({'A':[1,2,3,4]})\n",
    "df2 = pd.DataFrame({'A':[5,6,7,8]})\n",
    "dd = pd.concat([df1, df2], sort=False, ignore_index=True, axis=0)\n",
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
