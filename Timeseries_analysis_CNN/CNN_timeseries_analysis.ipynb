{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Input, Dense, Conv1D, Flatten, MaxPooling1D\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers.merge import concatenate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This Time series model example devided into 4 parts\n",
    "<ol>\n",
    "    <li>Univariate CNN Models</li>\n",
    "    <li>Multivariate CNN Models</li>\n",
    "    <li>Multi-Step CNN Models</li>\n",
    "    <li>Multivariate Multi-Step CNN Models</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Univariate CNN Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "divide the sequence into multiple input/output patterns called samples, \n",
    "where three time steps are used as input and one time step is used as \n",
    "output for the one-step prediction that is being learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 3\n",
    "n_feature = 1\n",
    "n = len(data)\n",
    "assert (input_dim + n_feature) < n\n",
    "def split_sequence(data, input_dim):\n",
    "    feature = []\n",
    "    label = []\n",
    "    start = 0\n",
    "    stop = start + input_dim\n",
    "    while stop < n:\n",
    "        feature.append(data[start:stop])\n",
    "        label.append(data[stop])\n",
    "        start += 1\n",
    "        stop += 1\n",
    "    return np.array(feature), np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = split_sequence(data, input_dim)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "X = X.reshape(X.shape[0], X.shape[1], n_feature)\n",
    "X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Anaconda\\lib\\site-packages\\keras\\optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2326dec94e0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(input_dim, n_feature)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=50, activation='relu'))\n",
    "model.add(Dense(units=1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.fit(X, y, epochs=1000, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[154.837]]\n"
     ]
    }
   ],
   "source": [
    "x_input = np.array([120, 130, 140])\n",
    "x_input = x_input.reshape((1, input_dim, n_feature))\n",
    "yhat = model.predict(x_input, verbose=5)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10],\n",
       "       [20],\n",
       "       [30]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Multivariate CNN models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It has 2 main type:\n",
    "    1. multiple input series\n",
    "    2. Multiple Parallel Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.multiple input series:\n",
    "A problem may have two or more parallel input time series and an output time series that is dependent on the input time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_1 = np.array([10, 20, 30, 40, 50, 60, 70, 80, 90, 100])\n",
    "feature_2 = np.array([15, 25, 35, 45, 55, 65, 75, 85, 95, 105])\n",
    "label = feature_1 + feature_2\n",
    "dataset = np.concatenate([feature_1[:, np.newaxis], feature_2[:, np.newaxis], label[:, np.newaxis]], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 10  15  25]\n",
      " [ 20  25  45]\n",
      " [ 30  35  65]\n",
      " [ 40  45  85]\n",
      " [ 50  55 105]\n",
      " [ 60  65 125]\n",
      " [ 70  75 145]\n",
      " [ 80  85 165]\n",
      " [ 90  95 185]\n",
      " [100 105 205]]\n"
     ]
    }
   ],
   "source": [
    "print(dataset)\n",
    "time_step = 3\n",
    "n_feature = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, time_step, feature_column, label_column):\n",
    "    n = len(data)\n",
    "    features = []\n",
    "    labels = []\n",
    "    for start in range(n-time_step+1):\n",
    "        feature = data[start: start+time_step , feature_column].tolist()\n",
    "        label = data[start+time_step-1, label_column].tolist()\n",
    "        features.append(feature)\n",
    "        labels.append(label)\n",
    "    return np.array(features), np.array(labels)\n",
    "X, y = split_data(dataset, time_step, [0, 1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model creation\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape= (time_step, n_feature)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2326f676b70>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[228.87364]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.array([[90, 95], [100, 105], [110, 115]])\n",
    "#test = np.array([[80, 85], [ 90,  95], [100, 105]])\n",
    "test = test.reshape((1, time_step, n_feature))\n",
    "model.predict(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively Each input series can be handled by a separate CNN and the output of\n",
    "each of these submodels can be combined before a prediction is made for the output\n",
    "sequence.We can refer to this as a multi-headed CNN model. It may offer more flexibility\n",
    "or better performance depending on the specifics of the problem that is being modeled.\n",
    "For example, it allows you to configure each sub-model differently for each input series,\n",
    "such as the number of filter maps and the kernel size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can define the first input model as a 1D CNN with an input layer that expects vectors with n_steps and 1 feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first input model\n",
    "visible1 = Input(shape=(time_step, 1))\n",
    "cnn1 = Conv1D(filters=64, kernel_size=2, activation='relu')(visible1)\n",
    "cnn1 = MaxPooling1D(pool_size=2)(cnn1)\n",
    "cnn1 = Flatten()(cnn1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second input model\n",
    "visible2 = Input(shape=(time_step, 1))\n",
    "cnn2 = Conv1D(filters=64, kernel_size=2, activation='relu')(visible2)\n",
    "cnn2 = MaxPooling1D(pool_size=2)(cnn2)\n",
    "cnn2 = Flatten()(cnn2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge = concatenate([cnn1, cnn2])\n",
    "dense = Dense(units=50, activation='relu')(merge)\n",
    "output = Dense(units=1)(dense)\n",
    "model = Model(inputs=[visible1, visible2], outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1, y = split_data(dataset, time_step, [0], 2)\n",
    "X2, y = split_data(dataset, time_step, [1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23270944160>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([X1, X2], y, epochs=100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = test[:, :, [0]]\n",
    "X2 = test[:, :, [1]]\n",
    "y_pred = model.predict([X1, X2], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[230.00555]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Multiple Parallel series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternate time series problem is the case where there are\n",
    "multiple parallel time series and a value must be predicted for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_1 = np.array([10, 20, 30, 40, 50, 60, 70, 80, 90, 100])\n",
    "feature_2 = np.array([15, 25, 35, 45, 55, 65, 75, 85, 95, 105])\n",
    "feature_3 = feature_1 + feature_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_multiple_parallel(data, time_step, feature_column, label_column):\n",
    "    n = len(data)\n",
    "    features = []\n",
    "    labels = []\n",
    "    for start in range(n-time_step):\n",
    "        feature = data[start: start+time_step , feature_column].tolist()\n",
    "        label = data[start+time_step, label_column].tolist()\n",
    "        features.append(feature)\n",
    "        labels.append(label)\n",
    "    return np.array(features), np.array(labels)\n",
    "dataset = np.concatenate([feature_1[:, np.newaxis], feature_2[:, np.newaxis], feature_3[:, np.newaxis]], axis = 1)\n",
    "time_step = 3\n",
    "X, y = split_data_multiple_parallel(dataset, time_step, [0, 1, 2], [0, 1, 2])\n",
    "n_feature = X.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define models\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(time_step, n_feature)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=50, activation='relu'))\n",
    "model.add(Dense(n_feature))\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2326f1cfef0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=1000, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[111.43784, 116.61249, 228.50899]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.array([[80,  85, 165], [ 90,  95, 185], [100, 105, 205]])\n",
    "test = test.reshape(1, test.shape[0], test.shape[1])\n",
    "model.predict(test, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.  multistep CNN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = np.array([10, 20, 30, 40, 50, 60, 70, 80, 90, 100])\n",
    "time_step = 3\n",
    "output_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_seq_multistep(data, time_step, output_size):\n",
    "    feature = []\n",
    "    label = []\n",
    "    for start in range(len(data)-time_step-output_size):\n",
    "        feature.append(data[start: start+ time_step])\n",
    "        label.append(data[start+ time_step: start+ time_step + output_size])\n",
    "    return np.array(feature), np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = split_seq_multistep(feature, time_step, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape from [n_sample, timestep, n_feature]\n",
    "n_feature = 1\n",
    "X = X.reshape((X.shape[0], X.shape[1], n_feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23273293da0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_step_out = 2\n",
    "# defining model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(X.shape[1], n_feature)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=50, activation='relu'))\n",
    "model.add(Dense(units=n_step_out))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.fit(X, y, epochs=1000, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.array([[80, 90, 100]])\n",
    "test = test.reshape((1, test.shape[1], n_feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[112.72062 , 125.181526]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(test, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.Multivariate Multi-Step CNN Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature1 = np.array([10, 20, 30, 40, 50, 60, 70, 80, 90, 100])\n",
    "feature1 = np.array([15, 25, 35, 45, 55, 65, 75, 85, 95, 105])\n",
    "label = feature_1 + feature_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.concatenate([feature_1[:, np.newaxis], feature_2[:, np.newaxis], label[:, np.newaxis]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_multivariate_multistep_data(data, n_step_in, n_step_out):\n",
    "    n = len(data)\n",
    "    feature = []\n",
    "    label = []\n",
    "    for start in range(n-n_step_in-n_step_out+1):\n",
    "        feature.append(np.squeeze(data[start:start+n_step_in]))\n",
    "        label.append(np.squeeze(data[start+n_step_in:start+n_step_in+n_step_out]))\n",
    "    return np.array(feature) , np.array(label)\n",
    "n_step_in, n_step_out = 3, 2\n",
    "X, y = split_multivariate_multistep_data(data, n_step_in, n_step_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 10  15  25]\n",
      "  [ 20  25  45]\n",
      "  [ 30  35  65]]\n",
      "\n",
      " [[ 20  25  45]\n",
      "  [ 30  35  65]\n",
      "  [ 40  45  85]]\n",
      "\n",
      " [[ 30  35  65]\n",
      "  [ 40  45  85]\n",
      "  [ 50  55 105]]\n",
      "\n",
      " [[ 40  45  85]\n",
      "  [ 50  55 105]\n",
      "  [ 60  65 125]]\n",
      "\n",
      " [[ 50  55 105]\n",
      "  [ 60  65 125]\n",
      "  [ 70  75 145]]\n",
      "\n",
      " [[ 60  65 125]\n",
      "  [ 70  75 145]\n",
      "  [ 80  85 165]]]\n"
     ]
    }
   ],
   "source": [
    "print(X)\n",
    "#print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23273977c50>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_feature = X.shape[2]\n",
    "n_output = y.shape[1]*y.shape[2]\n",
    "# model creation\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_step_in, n_feature)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=50, activation='relu'))\n",
    "model.add(Dense(units=n_output))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.fit(X, y.reshape((y.shape[0], y.shape[1] * y.shape[2])), epochs=8000, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.array([[ 80, 85, 165],[90, 95, 185], [100, 105, 205]])\n",
    "predict = model.predict(test.reshape(1, test.shape[0], test.shape[1]), verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[111.905685, 116.928825, 229.11    ],\n",
       "       [123.33852 , 129.6891  , 252.42561 ]], dtype=float32)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict.reshape(n_step_out, n_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 10,  15,  25],\n",
       "       [ 20,  25,  45],\n",
       "       [ 30,  35,  65],\n",
       "       [ 40,  45,  85],\n",
       "       [ 50,  55, 105],\n",
       "       [ 60,  65, 125],\n",
       "       [ 70,  75, 145],\n",
       "       [ 80,  85, 165],\n",
       "       [ 90,  95, 185],\n",
       "       [100, 105, 205]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
